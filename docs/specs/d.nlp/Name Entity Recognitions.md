
# Предложения по реорганизации entity_extraction.py для text.py

После анализа существующего кода, спецификации и требований к работе с текстовыми полями, предлагаю следующий план по усовершенствованию модуля `entity_extraction.py` и созданию подпакета `entity`, чтобы сделать его более универсальным и упростить `text.py`:

## 1. Архитектурные изменения

1. **Создать подпакет `entity` в рамках `pamola_core.utils.nlp`**:
    
    - Перенести основной функционал из `entity_extraction.py` в новый подпакет
    - Разделить на специализированные экстракторы по типам сущностей
2. **Базовая иерархия классов**:
    
    - `BaseEntityExtractor` (абстрактный класс с общим интерфейсом)
    - Специализированные экстракторы (наследники):
        - `JobPositionExtractor` (должности)
        - `OrganizationExtractor` (организации, включая университеты)
        - `SkillExtractor` (навыки и технологии)
        - `TransactionPurposeExtractor` (назначения платежей)
        - `GenericDictionaryExtractor` (универсальный экстрактор на основе словарей)
3. **Единый фабричный метод для создания экстракторов**:
    
    - `create_entity_extractor(entity_type: str, **kwargs)` - централизованное создание нужного экстрактора

## 2. Улучшения функциональности экстракции сущностей

1. **Стратегический подход к извлечению**:
    
    - Пайплайн с порядком применения методов:
        1. Поиск по словарю (наиболее точный)
        2. Применение NER моделей (средняя точность)
        3. Кластеризация неопознанных (наименее точная)
2. **Улучшенное разрешение коллизий**:
    
    - Приоритизация по длине совпадения (предпочтение более длинных фраз)
    - Приоритизация по уровню в иерархии категорий (более специфичные выше)
    - Возможность настройки стратегии через параметры
3. **Интеграция с обновленной системой кеширования**:
    
    - Использование `file_cache` и `memory_cache` для результатов экстракции
    - Кеширование загруженных словарей и обнаруженных моделей

## 3. Новые возможности для поддержки различных типов текстовых полей

1. **Настраиваемая загрузка иерархических словарей**:
    
    - Поддержка сложных иерархических структур через `CategoryDictionary`
    - Возможность указать различные словари для разных типов сущностей
2. **Атрибутный подход к результатам экстракции**:
    
    - Возвращение сущностей с полным набором атрибутов (категория, домен, уровень и т.д.)
    - Сохранение информации о конфликтах и альтернативных интерпретациях
3. **Универсальный API для различных типов текстовых полей**:
    
    - Единый метод `extract_entities(texts: List[str], entity_type: str, **kwargs)`
    - Параметризация по типу сущностей и стратегиям поиска

## 4. Оптимизации для text.py

1. **Перенос логики анализа из text.py в nlp модули**:
    
    - Категоризация сущностей → `category_matching.py`
    - Обработка конфликтов → функция разрешения в `entity_extraction.py`
    - Анализ языка → `language.py`
2. **Пайплайн для полного анализа текстового поля**:
    
    - Токенизация и нормализация через обновленный `tokenization.py`
    - Извлечение сущностей через новые экстракторы из `entity/`
    - Сопоставление с категориями через `category_matching.py`
    - Кластеризация остатков через `clustering.py`
3. **Упрощение text.py до координатора операций**:
    
    - Сосредоточение на сборе метрик, визуализации и формировании артефактов
    - Делегирование всех алгоритмических задач в модули nlp
    - Объединение результатов работы различных компонентов nlp

## 5. Примеры интерфейсов для новой архитектуры

```python
# Пример использования обновленного интерфейса из text.py
from pamola_core.utils.nlp.entity import create_entity_extractor
from pamola_core.utils.nlp.category_matching import CategoryDictionary

# Загрузка словаря категорий
categories = CategoryDictionary.from_file(dictionary_path)

# Создание подходящего экстрактора
extractor = create_entity_extractor(
    entity_type="job_position",  # или "organization", "skill", "transaction", etc.
    language=language,
    dictionary=categories.dictionary,
    match_strategy="specific_first"
)

# Извлечение сущностей с полной информацией
entities_results = extractor.extract_entities(text_values)

# Дополнительная обработка неразрешенных сущностей
if perform_clustering and entities_results["unresolved"]:
    clusters = cluster_by_similarity(entities_results["unresolved"], clustering_threshold)
    # Объединение с основными результатами...
```

## 6. Предлагаемая структура файлов

```
pamola_core/utils/nlp/
  ├── entity/
  │   ├── __init__.py
  │   ├── base.py                # Базовые классы экстракторов
  │   ├── job.py                 # Экстрактор должностей
  │   ├── organization.py        # Экстрактор организаций
  │   ├── skill.py               # Экстрактор навыков
  │   ├── transaction.py         # Экстрактор назначений платежей
  │   └── dictionary.py          # Универсальный экстрактор на основе словарей
  ├── category_matching.py       # Улучшенное сопоставление категорий
  ├── clustering.py              # Кластеризация текстов
  ├── base.py                    # Базовые классы и утилиты
  ├── cache.py                   # Система кеширования
  ├── compatibility.py           # Проверка зависимостей
  ├── language.py                # Обнаружение языка
  ├── stopwords.py               # Работа со стоп-словами
  └── tokenization.py            # Токенизация и обработка текста
```

Такой подход к реорганизации `entity_extraction.py` и созданию подпакета `entity` значительно упростит модуль `text.py`, делая его более поддерживаемым и расширяемым, а также позволит использовать функционал извлечения сущностей для различных типов текстовых полей.
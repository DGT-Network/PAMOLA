# I. Операции (operations.py)

## 1) Интеграция с генераторами

### Описание (кратко):

- Каждая операция (например, генерация имени, e-mail, телефона) получает на вход:
    
    - источник данных (файл, DataFrame),
        
    - директорию задачи `{task_dir}`,
        
    - список полей и вспомогательные параметры (например, указание пола для генерации имени),
        
    - флаги для управления режимом генерации (replace/enrich, сохранение карты замен, использование PRGN и т.д.),
        
    - ссылки на словари (при необходимости),
        
    - ключи для шифрования или псевдорандомизации.
        
- Операция связана с одним (или несколькими) генераторами, которые формируют фейковые данные и возвращают их для вставки в итоговый DataFrame или для подмены исходного значения.
    
- Могут быть генераторы случайного выбора из словаря, детерминированного (PRGN) и т.д.
    

### Рекомендации:

- Ввести **инверсию зависимостей**: операции вызывают базовый класс `BaseGenerator`, чтобы не зависеть от конкретной реализации.
    
- Использовать класс `GeneratorOperation`, где задаётся `generator`, `mapping_store_path`, `consistency_mechanism` и другие универсальные параметры.
    
- Передавать операции единый контекст (ID задачи, путь для сохранения данных, общие параметры), чтобы генератор мог корректно работать с маппингами и артефактами.
    

### Подсказки:

- **Подсказка 1**: Реализовать фабрику генераторов (pattern Factory), чтобы по типу операции (или типу данных) автоматически возвращать нужный экземпляр (`NameGenerator`, `EmailGenerator` и т.д.).
    
- **Подсказка 2**: Подумать о введении единого интерфейса для “конфигурации” генератора, чтобы операции могли гибко менять логику без переписывания кода (например, через JSON-параметры).
    
- **Подсказка 3**: Для удобства отладки — добавить режим “dry run” в операции, при котором генератор не меняет реальные данные, а лишь логирует, что было бы сгенерировано.
    

---

## 2) Управление маппингами

### Описание:

- Нужно сохранять 1-to-1 соответствие между исходными и новыми значениями (Mapping).
    
- Альтернативно использовать PRGN, где при одинаковом входном значении генерация будет детерминированно возвращать тот же результат. - предпочитетльный путь по умолчанию
    
- Указывается, что пользователь сам выбирает механизм: хранить маппинг в JSON (`MappingStore`) или использовать PRGN.
    

### Рекомендации:

- Явно задавать параметр `consistency_mechanism` = `mapping` или `prgn`.
    
- При `mapping` сохранять JSON-файл с соответствиями; при `prgn` достаточно хранить ключ и соль.
    
- Позволить опционально загружать ранее сохранённую карту замен, если требуется повторная идентичная обработка.
    

### Подсказки AI:

- **Подсказка 1**: Если в рамках одной задачи используется несколько операций, продумать общий MappingStore, чтобы консистентно заменять одни и те же значения во всех столбцах.
    
- **Подсказка 2**: Реализовать гибридный режим: часть полей маппить, часть — генерировать через PRGN (например, имена — через mapping, телефоны — через prgn).
    
- **Подсказка 3**: Создать веб-интерфейс или CLI-утилиту для просмотра/экспорта/редактирования готовых маппингов.
    

---

## 3) Обработка пакетных данных

### Описание (кратко):

- Встаёт вопрос, как эффективно обрабатывать большие объёмы данных, не загружая целиком в память.
    
- Предлагается пакетный (chunk-wise) режим.
    

### Имеющиеся ответы/рекомендации:

- Ввести параметр `batch_size` (например, 10 000 строк).
    
- Использовать стримовое чтение и запись (по частям).
    
- Минимизировать копирование данных между шагами: обновлять DataFrame “на месте” при замене (если тип данных позволяет).
    

### Подсказки AI:

- **Подсказка 1**: Организовать буферизацию и асинхронную обработку: пока один кусок данных генерируется, следующий уже загружается.
    
- **Подсказка 2**: Подключить мониторинг памяти (через `psutil` или другой инструмент) и динамически изменять `batch_size`.
    
- **Подсказка 3**: Для особенно больших данных рассмотреть распределённую обработку (Spark или Dask), сохранив единую логику генерации.
    

---

## 4) Метрики и артефакты

### Описание (кратко):

- Нужно включить статистику качества анонимизации (распределения, уникальность, корректность) и метрики производительности.
    

### Имеющиеся ответы/рекомендации:

- Сохранять в JSON в директории артефактов (`{task_dir}/artifacts`).
    
- Ключевые метрики:
    
    - распределение до/после,
        
    - процент уникальных значений,
        
    - корректность формата,
        
    - скорость обработки.
        
- При необходимости строить графики через `pamola_core.utils.visualization`.
    

### Подсказки AI:

- **Подсказка 1**: Ввести “оценку риска” (к примеру, вероятность обратной деанонимизации), если есть такой модуль.
    
- **Подсказка 2**: Хранить историю метрик за несколько итераций (в случае повторных запусков), чтобы отслеживать динамику.
    
- **Подсказка 3**: Дополнить отчёт сводкой по тому, сколько строк было пропущено или оставлено без изменений.
    

---

## 5) Общие параметры операций

### Описание (кратко):

- Требуется стандартизировать единый набор базовых параметров (field_name, mode, batch_size, consistency_mechanism и т.д.) для всех операций.
    

### Имеющиеся ответы/рекомендации:

- Создать унифицированный список:
    
    - `field_name`,
        
    - `mode` (`REPLACE`/`ENRICH`),
        
    - `output_field_name`,
        
    - `null_strategy`,
        
    - `batch_size`,
        
    - `generator_params` (JSON или dict),
        
    - `consistency_mechanism` (`mapping` или `prgn`),
        
    - `mapping_store_path`,
        
    - `task_folder`,
        
    - `save_data`,
        
    - и т.п.
        
- Давать разумные значения по умолчанию (mode=ENRICH, batch_size=10 000, consistency_mechanism=prgn и т.д.).
    

### Подсказки AI:

- **Подсказка 1**: Завести единый датакласс (например, `GeneratorOperationConfig`), который будет содержать все эти поля и проверку корректности.
    
- **Подсказка 2**: Сделать отдельные пресеты (например, “fast_mode”, “secure_mode”, “default_mode”).
    
- **Подсказка 3**: Включить параметр `dry_run` (см. выше), чтобы видеть, какие изменения **могут** произойти, до реального сохранения.
    

---

# II. Утилиты (utils.py)

## 6) Оптимизация загрузки словарей

### Описание (кратко):

- Нужно ускорить чтение и доступ к большим словарям, в том числе многоязычным, с учётом кэширования.
    

### Имеющиеся ответы/рекомендации:

- Двухуровневый кэш (в памяти + на диске).
    
- Ленивая загрузка (только при первом запросе).
    
- Автоопределение формата (txt/csv/json).
    
- Встроенные словари как резерв.
    

### Подсказки AI:

- **Подсказка 1**: Хранить словари в оптимизированном бинарном виде (Pickle, Parquet) и лишь при редком обновлении перегонять их из оригинальных txt-файлов.
    
- **Подсказка 2**: Создать сервис или singleton, который отвечает за словари, чтобы не размножать кэш по разным модулям.
    
- **Подсказка 3**: Для словарей, где требуется частый поиск (например, “есть ли это имя в списке?”), подумать об индексации (Trie, HashSet и т.д.).
    

---

## 7) Обработка многоязычности

### Описание (кратко):

- Нужно корректно обрабатывать разные языки/региональные особенности.
    

### Имеющиеся ответы/рекомендации:

- Везде, где нужен язык, вводить параметр `language`.
    
- Поддерживать определения языка (по символам) или устанавливать его явно.
    
- Сохранять файлы словарей в структурах вида `fake_data/<lang>/...`.
    

### Подсказки AI:

- **Подсказка 1**: Реализовать функцию “автоопределения” языка с порогом уверенности и логированием (если уверенность < 80%, записывать предупреждение).
    
- **Подсказка 2**: Расширять поддержку регионов и локализаций (дата-форматы, принятые варианты сокращений).
    
- **Подсказка 3**: Для китайского, японского и других иероглифических языков предусмотреть отдельную логику генерации (если это предполагается в дальнейшем).
    

---

## 8) Управление совместимостью

### Описание (кратко):

- Важно соблюдать совместимость с существующими утилитами `pamola_core.utils` (io, logging, progress, visualization).
    

### Имеющиеся ответы/рекомендации:

- Все операции чтения/записи файлов вести через `pamola_core.utils.io`.
    
- Логирование — через `pamola_core.utils.logging`.
    
- Прогресс — через `pamola_core.utils.progress`.
    
- Генерация отчётов/графиков — через `pamola_core.utils.visualization`.
    

### Подсказки AI:

- **Подсказка 1**: Если появится необходимость, сделать адаптер на случай, если в будущем придётся подключать другую систему логирования (например, Logstash/Elastic).
    
- **Подсказка 2**: Подумать о едином формате конфигурации для `pamola_core.utils` (например, YAML), чтобы при запуске операции все настройки (папки, логи, и т.д.) подтягивались автоматически.
    
- **Подсказка 3**: Использовать декораторы для унифицированного контроля ошибок и записи их в логи.
    

---

## 9) Расширение функций обнаружения паттернов

### Описание (кратко):

- Нужно улучшить определение пола, языка, других характеристик (NLP, паттерны).
    

### Имеющиеся ответы/рекомендации:

- Использовать вспомогательные поля (например, хранить пол отдельно).
    
- Для языка — простое определение по символам или подключать `pamola_core.utils.nlp.language`.
    
- Хранить эту логику в отдельных модулях (например, `commons/patterns.py`).
    

### Подсказки AI:

- **Подсказка 1**: Внедрить небольшие ML-модели (например, логистическая регрессия) для определения пола по имени, если словари-окончания не дают достаточной точности.
    
- **Подсказка 2**: Для многоязычности — использовать модели типа langdetect, fasttext language identification (при условии, что нет строгих ограничений).
    
- **Подсказка 3**: Дополнить обнаружение “особых категорий” (например, “VIP”, “senior”) при генерации анонимных данных, если важно скрыть статус.
    

---

## 10) Унификация работы с PRF/PRGN

### Описание (кратко):

- Детерминированная генерация (PRGN) наряду с классическим mapping; общие ключи и соль.
    

### Имеющиеся ответы/рекомендации:

- Создать единый интерфейс (`PRGNEngine` или `DeterministicGenerator`) для получения псевдослучайных значений.
    
- Инкапсулировать детали генерации (по ключу, соли, алгоритму).
    
- Позволить задавать seed на уровне операции или глобально.
    

### Подсказки AI:

- **Подсказка 1**: Реализовать разные алгоритмы PRGN (SHA256, HMAC и т.п.) с выбором пользователем.
    
- **Подсказка 2**: Добавить возможность обновления seed/соли после N строк, чтобы усложнить обратную инженерию (если важна безопасность).
    
- **Подсказка 3**: Для тестов и аудита — включить режим отладки, в котором фиксируется начальный seed и логируются первые несколько “случайных” чисел.
    

---

# III. Дополнительные архитектурные вопросы

## 11) Разделение ответственности

### Описание (кратко):

- Операции (operations.py) и специализированные модули генераторов (generators/). Где какая логика?
    

### Имеющиеся ответы/рекомендации:

- В `operations.py` — интеграция с инфраструктурой (запуск, метрики, сохранение результатов).
    
- В `generators/` — вся генерация (NameGenerator, PhoneGenerator и т.д.).
    
- В `commons/` или `dictionaries/` — хранение словарей, кэш, валидаторы.
    

### Подсказки AI:

- **Подсказка 1**: Рассмотреть шаблон “плагины” — чтобы новые типы генераторов подключались автоматически при их добавлении в папку `generators/`.
    
- **Подсказка 2**: Внедрить dependency injection-контейнер (необязательно, но упростит тестирование и замену зависимостей).
    
- **Подсказка 3**: Документировать, какие методы должны быть в каждом генераторе, чтобы новые разработчики могли легко добавить свой.
    

---

## 12) Обработка ошибок

### Описание (кратко):

- Необходимо единообразно обрабатывать отсутствие словарей, неверные параметры и пр.
    

### Имеющиеся ответы/рекомендации:

- Делить ошибки на некритические (логируем, продолжаем работу) и критические (вызываем исключение).
    
- Иметь `OperationResult` со статусом, списком ошибок.
    
- Логировать через `pamola_core.utils.logging`.
    

### Подсказки AI:

- **Подсказка 1**: Создать иерархию исключений (например, `FakeDataError`, `DictionaryNotFoundError`), чтобы в коде чётко отличать типы проблем.
    
- **Подсказка 2**: При возникновении ошибок продолжать обработку следующего батча (если это допустимо) и складывать проблемные строки в отдельный лог.
    
- **Подсказка 3**: Для крупных систем — предусмотреть механизм алертинга (email, Slack, Telegram) при критических сбоях.
    

---

## 13) Расширяемость

### Описание (кратко):

- Нужно, чтобы без изменения базовой архитектуры можно было добавить новые типы фейковых данных (например, “номера машин”, “паспортные данные”).
    

### Имеющиеся ответы/рекомендации:

- Базовый класс `BaseGenerator`.
    
- Регистрация генераторов в системе.
    
- Параметризация операций для работы с любым генератором.
    

### Подсказки AI:

- **Подсказка 1**: Сделать “метаданные” для каждого генератора, чтобы автоматически формировать документацию, список параметров.
    
- **Подсказка 2**: Поддержать “композицию” генераторов (например, сгенерировать ФИО + дату рождения сразу).
    
- **Подсказка 3**: Для отладки новых генераторов — ввести флаг `verbose`, чтобы видеть пошагово, как генерируется значение.
    

---

## 14) Настройка логирования

### Описание (кратко):

- Нужно оптимизировать детальность и структуру логов, чтобы их можно было применять и для аудита, и для отладки.
    

### Имеющиеся ответы/рекомендации:

- Использовать `pamola_core.utils.logging`.
    
- Стандартизировать уровни логов.
    
- Включать контекст (operation_id, batch_number, …).
    
- Не логировать каждую строку при большом объёме данных.
    

### Подсказки AI:

- **Подсказка 1**: Собирать логи разных операций в единый log-файл (но при этом сохранять операции отдельными метками).
    
- **Подсказка 2**: При использовании `DEBUG`-режима — логировать пример исходных и сгенерированных значений (с учётом безопасной маскировки).
    
- **Подсказка 3**: Использовать асинхронное логирование (через очередь), чтобы не замедлять процесс обработки данных.
    

---

## 15) Конфигурация по умолчанию

### Описание (кратко):

- Нужно определить разумные default-параметры (batch_size, null_strategy, mode, язык и т.д.).
    

### Имеющиеся ответы/рекомендации:

- `batch_size = 10000`, `null_strategy = "PRESERVE"`, `mode = "ENRICH"`, `language = "en"`, `consistency_mechanism = "prgn"`.
    
- Всё это можно хранить в общем конфиге.
    

### Подсказки AI:

- **Подсказка 1**: Реализовать простую логику “автоопределения” языка по первым строкам данных (если `language` не указан).
    
- **Подсказка 2**: Задать лимит на количество параметров, которые пользователь должен указывать — остальные брать из конфига, чтобы упростить вызов.
    
- **Подсказка 3**: Автоматически подбирать `batch_size` в зависимости от объёма данных и available RAM (эвристика).
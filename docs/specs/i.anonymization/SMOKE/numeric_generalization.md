# Mini SRS: Numeric Generalization Smoke Task

## 1. Purpose

Provide a self-contained smoke-test for the **NumericGeneralizationOperation**, demonstrating:

* Correct end-to-end execution of multiple generalization steps via a BaseSmokeTask-derived class.
* Consistent collection of metrics and generation of visualizations.
* Clear template for other smoke-tests (categorical generalization, noise addition, pseudonymization, masking, etc.).

## 2. Scope & Environment

* **Project root:** `D:\VK\_DEVEL\PAMOLA.CORE`
* **Smoke framework:** `scripts/smoke/base/base_smoke_task.py` (abstract BaseSmokeTask)
* **Concrete task:** `scripts/smoke/numeric_generalization.py` (NumericGeneralizationSmokeTask)
* **Data repository:** `D:\VK\_DEVEL\PAMOLA.CORE\DATA`
* **Input file:** `DATA/raw/bank_txs/txs.csv` (UTF-8, comma delimiter)
* **Task ID:** `numerictxs`
* **Working directory:** `DATA/processed/smoke/numerictxs`

  * **Output CSVs:** `.../output/{field}_generalized.csv`
  * **Artifacts (JSON, PNG):** saved in `task_dir` root

## 3. Code Standards

Every smoke-task module must start with the PAMOLA header:

```python
"""
PAMOLA.CORE - Privacy-Preserving AI Data Processors
----------------------------------------------------
Module:        Numeric Generalization Smoke Test
Package:       scripts.smoke
Version:       1.0.0
Status:        stable
Author:        PAMOLA Core Team
Created:       2025-05-21
License:       BSD 3-Clause
Description:
    Smoke test for numeric generalization operations on banking transaction dataset.
    Built on BaseSmokeTask template for consistency with other operation tests.
"""
```

* All inline comments in English.
* Each concrete task derives from `BaseSmokeTask` and implements:

  1. `get_default_config()` – returns the default JSON config dict.
  2. `create_operation(field_config, vis_settings)` – instantiates the specific `AnonymizationOperation`.
  3. `get_expected_steps(field_config)` – returns integer number of progress steps.

## 4. Configuration

* Stored in `configs/{task_id}.json`.
* Auto-generated on first run via `BaseSmokeTask.load_or_create_config()`.
* Editable thereafter.
* **Default config example** provided by `get_default_config()`:

```json
{
  "task_id": "numerictxs",
  "operation_type": "numeric_generalization",
  "input_path": "raw/bank_txs/txs.csv",
  "output_dir": "processed/smoke/numerictxs",
  "encoding": "utf-8",
  "delimiter": ",",
  "fields": [
    {
      "name": "Age",
      "strategy": "binning",
      "mode": "REPLACE",
      "params": {"bin_count": 10},
      "visualizations": ["histogram", "distribution"],
      "expected_steps": 6
    },
    {
      "name": "Account Balance",
      "strategy": "rounding",
      "mode": "ENRICH",
      "params": {"precision": 2},
      "visualizations": ["histogram", "box"],
      "expected_steps": 6
    }
  ],
  "visualization_settings": {
    "backend": "plotly",
    "include_timestamp": false,
    "theme": null,
    "default_visualizations": ["histogram", "distribution"]
  },
  "operation_settings": {
    "null_strategy": "PRESERVE",
    "batch_size": 10000,
    "use_cache": true,
    "use_encryption": false
  }
}
```

## 5. Logging & Progress

* **Logging:** via `pamola_core/utils/logging.configure_task_logging()`, logs written to `logs/{task_id}.log`.
* **Progress:** each `execute_operation` uses `ProgressTracker(total, description, unit)` from `pamola_core/utils/progress.py`, with `total` from `get_expected_steps()`.
* **Logger setup:** `BaseSmokeTask.setup_logging(task_id)` and `BaseSmokeTask.run_smoke_test()` handle initialization.

## 6. Execution Flow

1. **run_smoke_test()** (in `BaseSmokeTask`):
   * Initialize logging via `configure_task_logging()`.
   * Create task instance and call `run()`.
   * Return exit code (0 for success, 1 for failure).

2. **Task execution flow:**
   * Load or create config via `load_or_create_config()`.
   * Setup directories (`task_dir`, `output`, etc.) with smart cleanup.
   * Load input data using `read_full_csv()`.

3. **Data source management:**
   * First operation: `DataSource.from_file_path(input_path, name="main", load=True)`.
   * Subsequent operations: `DataSource.from_dataframe(result_df, name="main")`.

4. **Per-field iteration:** for each entry in `config["fields"]`:
   1. Instantiate operation via `create_operation(field_config, vis_settings)`.
   2. Call `execute_operation(operation, data_source, index, field_config)`:
      * Create progress tracker with `get_expected_steps()`.
      * `operation.execute(...)` writes CSV to `output` and artifacts to `task_dir`.
      * Enhanced artifact categorization with field names and categories.
      * Extract result DataFrame using `_extract_result_dataframe()`.
      * Close progress tracker.

5. **Summary report:**
   * Generated by `generate_summary_report()`.
   * Includes `reporter.operations`, `reporter.artifacts`, and physical file inventory.
   * Enhanced with operation type and field-specific artifact grouping.
   * Saved as `DATA/reports/{task_id}_report.json`.

## 7. Visualization Types

* **Histogram** (for binning and rounding)
* **Bar Chart** (frequency per bin for categorical results)
* **Distribution comparison** (before vs. after)
* **Box plots** (for continuous data analysis)

All built via `pamola_core/utils/visualization.py`:
* **Primary backend:** Plotly (as per SRS requirement)
* **Fallback backend:** Matplotlib
* **Thread-safe context:** isolated visualization generation
* **Configuration:** via `visualization_settings` in config

## 8. Architecture Components

### 8.1 BaseSmokeTask (Abstract Base Class)

**Location:** `scripts/smoke/base/base_smoke_task.py`

**Key responsibilities:**
* Universal infrastructure (logging, config, directories, reporting)
* Generic operation execution workflow
* Artifact collection and categorization
* Progress tracking and error handling

**Abstract methods to implement:**
```python
@abstractmethod
def get_default_config(self) -> Dict[str, Any]

@abstractmethod  
def create_operation(self, field_config: FieldConfig, vis_settings: VisualizationSettings) -> AnonymizationOperation

@abstractmethod
def get_expected_steps(self, field_config: FieldConfig) -> int
```

### 8.2 TaskReporter (Enhanced)

**Features:**
* Field-based artifact categorization
* Category-based filtering (`output`, `metrics`, `visualization`)
* Enhanced artifact metadata with timestamps and descriptions

**Methods:**
```python
def add_artifact(self, artifact_type, path, description, category=None, field_name=None)
def get_artifacts_by_field(self, field_name) -> List[Dict[str, Any]]
def get_artifacts_by_category(self, category) -> List[Dict[str, Any]]
```

### 8.3 NumericGeneralizationSmokeTask (Concrete Implementation)

**Location:** `scripts/smoke/numeric_generalization.py`

**Specializations:**
* Numeric-specific configuration with operation settings
* Support for strategies: `binning`, `rounding`, `range`
* Strategy metadata via `get_supported_strategies()`
* Visualization configuration for numeric data

## 9. Functional Requirements

| ID  | Requirement                                                                                             |
| --- | ------------------------------------------------------------------------------------------------------- |
| FR1 | Load and validate CSV according to `config` using `read_full_csv()`.                                    |
| FR2 | Instantiate and execute one `NumericGeneralizationOperation` per field via `create_operation()`.        |
| FR3 | Save each field's generalized CSV in `task_dir/output` with standardized naming.                        |
| FR4 | Save per-field metrics (JSON) and visualizations (PNG) in `task_dir` root.                             |
| FR5 | Report progress via `ProgressTracker(total, description, unit)` using `get_expected_steps()`.           |
| FR6 | Provide default config via `get_default_config()` and support manual edits of `configs/{task_id}.json`. |
| FR7 | Log all steps (info, warning, error) to `logs/{task_id}.log` via `configure_task_logging()`.           |
| FR8 | Generate final JSON report in `DATA/reports/{task_id}_report.json` with enhanced metadata.             |
| FR9 | Use Plotly as primary visualization backend, fallback to Matplotlib via `visualization_settings`.       |
| FR10| Support template inheritance via `BaseSmokeTask` for other operation types.                            |
| FR11| Enhanced artifact categorization with field names and categories.                                      |
| FR12| Universal result extraction via `_extract_result_dataframe()` supporting any operation mode.          |

## 10. Non-Functional Requirements

* **Idempotence:** repeated runs use smart cleanup preserving logs, cleaning only artifacts.
* **Performance:** complete < 30s for ~100k records with progress tracking.
* **Extensibility:** new smoke-tasks add minimal code by overriding three abstract methods.
* **Standards compliance:** English comments, PAMOLA header, consistent file structure.
* **Thread safety:** visualization and file writes safe for concurrent contexts.
* **Template reusability:** `BaseSmokeTask` provides 90%+ of infrastructure for any operation type.

## 11. Template Usage for Other Operations

### Creating new smoke tests:

```python
class CategoricalGeneralizationSmokeTask(BaseSmokeTask):
    def __init__(self):
        super().__init__("categorical_gen", "categorical_generalization")
    
    def get_default_config(self):
        return {
            "fields": [
                {"name": "Category", "strategy": "hierarchy", "mode": "REPLACE"}
            ],
            "visualization_settings": {"backend": "plotly"}
        }
    
    def create_operation(self, field_config, vis_settings):
        return CategoricalGeneralizationOperation(...)
    
    def get_expected_steps(self, field_config):
        return 5  # Different step count for categorical operations
```

### Supported operation types:
* **Numeric generalization** - `binning`, `rounding`, `range`
* **Categorical generalization** - `suppression`, `hierarchy`, `k-anonymity`
* **Noise addition** - `gaussian`, `laplace`, `uniform`
* **Pseudonymization** - `hash`, `tokenization`, `format_preservation`
* **Masking** - `partial`, `full`, `pattern_based`

## 12. File Structure

```
D:\VK\_DEVEL\PAMOLA.CORE\
├── scripts/
│   └── smoke/
│       ├── base/
│       │   └── base_smoke_task.py     # Abstract base class
│       └── numeric_generalization.py  # Concrete implementation
├── configs/
│   └── numerictxs.json               # Auto-generated configuration
├── logs/
│   └── numerictxs.log                # Task execution logs
└── DATA/
    ├── raw/bank_txs/
    │   └── txs.csv                   # Input dataset
    ├── processed/smoke/numerictxs/
    │   ├── output/                   # Generated CSV files
    │   ├── *.json                    # Metrics files
    │   └── *.png                     # Visualization files
    └── reports/
        └── numerictxs_report.json    # Summary report
```

---

*Created:* 2025-05-21 • *Author:* PAMOLA Core Team • *Updated:* 2025-05-21
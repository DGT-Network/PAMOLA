# Обновленная архитектура пакета pamola_core.profiling

## Основные принципы

- Четкое разделение на базовые компоненты и специализированные анализаторы данных
- Устранение дублирования кода и четкая ответственность каждого модуля
- Абстрактные интерфейсы для поддержки расширяемости
- Единый подход к обработке различных типов данных
- Специализированные анализаторы для каждого типа данных
- Визуализация вынесена в общий пакет pamola_core.utils

## Структура пакета

### 1. `pamola_core/profiling/commons/`

Этот подпакет содержит базовую инфраструктуру и абстракции:

#### `base.py`

- Абстрактные базовые классы для анализаторов и операций
- Базовые интерфейсы, определяющие контракты между компонентами
- Общие типы результатов профилирования

```python
class BaseAnalyzer:
    """Abstract base class for all data analyzers."""
    
    def analyze(self, df, field_name, **kwargs):
        """Execute analysis and return results."""
        raise NotImplementedError

class BaseOperation:
    """Abstract base class for profiling operations."""
    
    def execute(self, df, reporter, profile_type, **kwargs):
        """Execute the operation and report results."""
        raise NotImplementedError
        
class AnalysisResult:
    """Container for analysis results with metadata and artifact references."""
    
    def __init__(self, stats, field_name=None, data_type=None):
        self.stats = stats
        self.field_name = field_name
        self.data_type = data_type
        self.artifacts = []
```

#### `data_types.py`

- Определения типов данных и перечислений, используемых в профилировании
- Константы и настройки для профилирования

```python
from enum import Enum

class DataType(Enum):
    """Enumeration of data types for profiling."""
    NUMERIC = "numeric"
    CATEGORICAL = "categorical"
    TEXT = "text"
    LONGTEXT = "longtext"
    DATE = "date"
    DATETIME = "datetime"
    EMAIL = "email"
    PHONE = "phone"
    MVF = "multi_valued"
    JSON = "json"
    ARRAY = "array"
    
class PrivacyLevel(Enum):
    """Enumeration of privacy levels for fields."""
    PUBLIC = "public"
    RESTRICTED = "restricted"
    SENSITIVE = "sensitive"
    IDENTIFIER = "identifier"
```

#### `helpers.py`

- Вспомогательные функции для определения типов данных и предобработки
- Функции для обнаружения и преобразования специфических форматов (JSON, массивы)

```python
def infer_data_type(series):
    """Infer the data type of a pandas Series."""
    # Implementation
    
def prepare_field_for_analysis(df, field_name):
    """Prepare a field for analysis, handling missing values etc."""
    # Implementation
    
def detect_json_field(series):
    """Detect if a field contains JSON data."""
    # Implementation
    
def detect_array_field(series):
    """Detect if a field contains array data."""
    # Implementation
    
def parse_field(series, parser_func=None):
    """Parse a field using the provided parser function."""
    # Implementation
```

### 2. `pamola_core/profiling/analyzers/`

Этот подпакет содержит специализированные анализаторы для различных типов данных:

#### `categorical.py`

- Обобщенный анализ категориальных полей
- Работа с частотным распределением, словарями и т.д.

```python
from pamola_core.profiling.commons.base import BaseAnalyzer, AnalysisResult


class CategoricalAnalyzer(BaseAnalyzer):
    """Analyzer for categorical fields."""

    def analyze(self, df, field_name, **kwargs):
        """Analyze a categorical field."""
        # Implementation

    def create_dictionary(self, df, field_name, **kwargs):
        """Create a frequency dictionary for categorical values."""
        # Implementation
```

#### `numeric.py`

- Анализ числовых полей
- Статистические методы и распределения

#### `text.py`

- Анализ текстовых полей
- Работа с короткими текстами, их структурой и распределением длин

#### `longtext.py`

- Специализированный анализ для длинных текстов
- Извлечение сущностей (NER)
- Интеграция с LLM для анализа

#### `email.py`

- Специализированный анализ для email-адресов
- Валидация, извлечение доменов, паттернов и т.д.

```python
from pamola_core.profiling.commons.base import BaseAnalyzer, AnalysisResult


class EmailAnalyzer(BaseAnalyzer):
    """Analyzer for email fields."""

    def analyze(self, df, field_name, **kwargs):
        """Analyze an email field."""
        # Implementation

    def extract_domains(self, df, field_name, **kwargs):
        """Extract domains from email addresses."""
        # Implementation

    def validate_emails(self, df, field_name, **kwargs):
        """Validate email addresses."""
        # Implementation
```

#### `phone.py`

- Специализированный анализ для телефонных номеров
- Парсинг, валидация, извлечение компонентов

```python
from pamola_core.profiling.commons.base import BaseAnalyzer, AnalysisResult


class PhoneAnalyzer(BaseAnalyzer):
    """Analyzer for phone number fields."""

    def analyze(self, df, field_name, **kwargs):
        """Analyze a phone number field."""
        # Implementation

    def parse_phone_numbers(self, df, field_name, **kwargs):
        """Parse phone numbers into components."""
        # Implementation

    def detect_messengers(self, df, field_name, **kwargs):
        """Detect messenger references in phone comments."""
        # Implementation
```

#### `date.py`

- Специализированный анализ для дат и времени
- Парсинг, валидация, статистика по периодам

#### `correlation.py`

- Анализ корреляций между различными полями
- Поддержка различных типов корреляций

#### `mvf.py`

- Анализ многозначных полей (Multi-Valued Fields)
- Парсинг и анализ полей со списками значений

#### `group.py`

- Анализ групповых вариаций
- Работа с группами данных (например, по resume_id)

### 4. `pamola_core/utils/visualization.py`

Модуль для создания визуализаций результатов анализа:

```python
def plot_categorical_distribution(data, title=None, **kwargs):
    """Create a bar chart for categorical data distribution."""
    # Implementation
    
def plot_numeric_distribution(data, title=None, **kwargs):
    """Create a histogram for numeric data distribution."""
    # Implementation
    
def plot_correlation_matrix(matrix, title=None, **kwargs):
    """Create a heatmap for correlation matrix."""
    # Implementation
    
def plot_email_domains(domains, title=None, **kwargs):
    """Create a visualization for email domain distribution."""
    # Implementation
    
def plot_phone_distribution(phone_data, title=None, **kwargs):
    """Create a visualization for phone number components."""
    # Implementation
```

## Основные операции профилирования

Операции построены на основе анализаторов и предоставляют удобный интерфейс для использования в задачах профилирования:

```python
class CategoricalFieldOperation(BaseOperation):
    """Operation for analyzing categorical fields."""

    def __init__(self, field_name, top_n=20, generate_visualization=True):
        self.field_name = field_name
        self.top_n = top_n
        self.generate_visualization = generate_visualization
        self.analyzer = CategoricalAnalyzer()

    def execute(self, df, reporter, profile_type, **kwargs):
        """Execute the operation on the DataFrame."""
        result = self.analyzer.analyze(
            df,
            self.field_name,
            top_n=self.top_n
        )

        # Save results
        from pamola_core.utils.io import save_profiling_results
        path = save_profiling_results(result.stats, profile_type, f"{self.field_name}_stats")
        reporter.add_artifact("json", path, f"{self.field_name} analysis")

        # Generate visualizations if needed
        if self.generate_visualization and result.stats.get('top_values'):
            from pamola_core.utils.visualization import plot_categorical_distribution
            fig = plot_categorical_distribution(
                result.stats['top_values'],
                f"{self.field_name} Distribution"
            )
            from pamola_core.utils.io import save_plot
            plot_path = save_plot(fig, profile_type, f"{self.field_name}_distribution")
            reporter.add_artifact("png", plot_path, f"{self.field_name} distribution visualization")

        return result
```

## Поддержка JSON и массивов

Для полей с JSON или массивами предусмотрены специальные преобразователи:

```python
class JsonFieldAnalyzer(BaseAnalyzer):
    """Analyzer for fields containing JSON data."""
    
    def analyze(self, df, field_name, **kwargs):
        """Analyze a field containing JSON data."""
        # Parse JSON
        import json
        
        # Implementation
        
class ArrayFieldAnalyzer(BaseAnalyzer):
    """Analyzer for fields containing array data."""
    
    def analyze(self, df, field_name, separator=",", **kwargs):
        """Analyze a field containing array data."""
        # Parse array
        
        # Implementation
```

## Взаимодействие с существующими задачами

Для поддержки обратной совместимости с существующими задачами профилирования (`profile_ident.py`, `profile_details.py`, `profile_contacts.py`) создадим адаптеры или фасады:

```python
def analyze_name_fields_section(df, reporter, profile_type):
    """Legacy adapter for name fields analysis."""
    name_analyzer = CategoricalAnalyzer()
    
    for field in ['first_name', 'last_name', 'middle_name']:
        if field in df.columns:
            operation = CategoricalFieldOperation(field)
            operation.execute(df, reporter, profile_type)
            
def analyze_emails(df, reporter, profile_type):
    """Legacy adapter for email analysis."""
    email_analyzer = EmailAnalyzer()
    email_operation = EmailOperation('email')
    email_operation.execute(df, reporter, profile_type)
```

## Преимущества новой архитектуры

1. **Специализация**: Каждый тип данных имеет свой специализированный анализатор
2. **Расширяемость**: Легко добавлять новые анализаторы и операции
3. **Гибкость**: Поддержка сложных типов данных (JSON, массивы)
4. **Повторное использование**: Общие компоненты выделены в базовые классы
5. **Интеграция**: Поддержка анализа с помощью LLM и NER для длинных текстов
6. **Организация**: Четкое разделение ответственности между компонентами